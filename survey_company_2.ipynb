{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from numpy import nan as NA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the filename to be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = str(input(\"enter the name of the file: \"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load file from input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_combined = pd.concat(pd.read_excel(file_name + '.xlsx',ignore_index=True, sheet_name=None, header=26))\n",
    "data_raw = pd.read_excel(file_name + '.xlsx', sheet_name=None, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list with the sheetnames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet_list = list(data_raw.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list containing only the movements (and thus number of movements) from the sheetnames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movement_list = []\n",
    "for sheet in sheet_list:\n",
    "        if 'Movement' in sheet:\n",
    "            movement_list.append(sheet)\n",
    "number_of_movements = len(movement_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a series containing only the PCU totals, per 15 minute interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_variables = ['Hourly Total', 'Hourly Average', 'Session Total', 'Session Average', 'TIME']\n",
    "\n",
    "for i in remove_variables:\n",
    "    data_combined = data_combined.drop(data_combined[(data_combined['TIME'] == i)].index)\n",
    "    \n",
    "cleaned_PCU_totals = data_combined['PCU TOTAL'].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape the series as an array of columns as 15 minute time intervals and rows as the movements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_totals = np.array(cleaned_PCU_totals)\n",
    "number_of_time_intervals = len(arr_totals)/number_of_movements\n",
    "organised_PCU_totals = arr_totals.reshape(number_of_movements, int(number_of_time_intervals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify the indices at which to split the array, such that AM, inter and PM peaks can be found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_time_intervals = int(input(\"Enter the number of intervals: \"))\n",
    "split_locations = []\n",
    "split_index = 0\n",
    "for interval in range(number_of_time_intervals-1):\n",
    "    split_index = (int(input(\"How many hours are there in interval \" + str(interval+1) + \": \"))*4) + split_index\n",
    "    split_locations.append(split_index)\n",
    "\n",
    "survey_intervals = np.hsplit(organised_PCU_totals,split_locations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total the columns (15 minute intervals), then calculate the rolling hour sum (Four consequetive columns). Drop null values which are the first three times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_hour_totals =[]\n",
    "for i in survey_intervals:\n",
    "    quarterly_sum = np.sum(i , axis=0)\n",
    "    quarterly_sum_df = pd.DataFrame(quarterly_sum)\n",
    "    rolling_hour_totals.append(quarterly_sum_df.rolling(4,).sum().dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display rolling hour PCU total, for the 15 minute intervals in the data, the first non-zero value is the first time interval in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print( \"The rolling hour totals, per 15 minute time interval (in PCUs) are: \\n\" + str(rolling_hour_totals))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the maximum values, i.e. the peaks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The peak values are: \")\n",
    "for survey in rolling_hour_totals:\n",
    "    x=np.array(survey)\n",
    "    print(x.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
